create table if not exists users (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table users enable row level security;
drop policy if exists "public read" on users;
create policy "public read" on users for select using (true);

create table if not exists contracts (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table contracts enable row level security;
drop policy if exists "public read" on contracts;
create policy "public read" on contracts for select using (true);

create table if not exists groups (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table groups enable row level security;
drop policy if exists "public read" on groups;
create policy "public read" on groups for select using (true);

create table if not exists txns (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table txns enable row level security;
drop policy if exists "public read" on txns;
create policy "public read" on txns for select using (true);

create table if not exists bets (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table bets enable row level security;
drop policy if exists "public read" on bets;
create policy "public read" on bets for select using (true);

create table if not exists comments (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table comments enable row level security;
drop policy if exists "public read" on comments;
create policy "public read" on comments for select using (true);

create table if not exists incoming_writes (
  id bigint generated always as identity primary key,
  event_id text null, /* can be null for writes generated by manual import */
  doc_kind text not null,
  write_kind text not null,
  doc_id text not null,
  data jsonb not null,
  ts timestamp not null,
  processed boolean not null default false
);
alter table incoming_writes enable row level security;
create index if not exists incoming_writes_ts on incoming_writes (ts desc);
create index if not exists incoming_writes_processed_ts on incoming_writes (processed, ts desc);

create or replace function get_document_table(doc_kind text)
  returns text
  language plpgsql
as
$$
begin
  return case doc_kind
    when 'txn' then 'txns'
    when 'user' then 'users'
    when 'group' then 'groups'
    when 'contract' then 'contracts'
    when 'contractBet' then 'bets'
    when 'contractComment' then 'comments'
    else null
  end;
end
$$;

create or replace function replicate_writes_process_one(r incoming_writes)
  returns boolean
  language plpgsql
as
$$
declare dest_table text;
declare replicated_id text;
begin
  dest_table = get_document_table(r.doc_kind);
  if dest_table = null then
    raise warning 'Invalid document kind.';
    return false;
  end if;
  if r.write_kind = 'create' or r.write_kind = 'update' then
    execute format(
      'insert into %1$I (id, data, fs_updated_time) values (%2$L, %3$L, %4$L)
       on conflict (id) do update set data = %3$L, fs_updated_time = %4$L
       where %1$I.fs_updated_time <= %4$L
       returning id;',
      dest_table, r.doc_id, r.data, r.ts
    ) into replicated_id;
  elsif r.write_kind = 'delete' then
    execute format(
      'delete from %1$I where id = %2$L and fs_updated_time <= %3$L',
      dest_table, r.doc_id, r.ts
    ) into replicated_id;
  else
    raise warning 'Invalid write kind.';
    return false;
  end if;
  return true;
end
$$;

create or replace function replicate_writes_process_all()
  returns table(succeeded boolean, n bigint)
  language plpgsql
as
$$
begin
  return query with updates as (
    select r.id, replicate_writes_process_one(r) as succeeded
    from incoming_writes as r
    where r.processed = false
    order by r.ts desc /* apply more recent writes first is less total work */
  ), writes as (
    update incoming_writes
    set processed = updates.succeeded
    from updates where incoming_writes.id = updates.id
  )
  select u.succeeded, count(u.succeeded) as n from updates as u group by u.succeeded;
end
$$;

create or replace function replicate_writes_process_new()
  returns trigger
  language plpgsql
as
$$
begin
  new.processed = replicate_writes_process_one(new);
  return new;
end
$$;

drop trigger if exists replicate_writes on incoming_writes;
create trigger replicate_writes
before insert on incoming_writes for each row
execute function replicate_writes_process_new();
