/* enable `explain` via the HTTP API for convenience */
alter role authenticator set pgrst.db_plan_enabled to true;
notify pgrst, 'reload config';

create table if not exists users (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table users enable row level security;
drop policy if exists "public read" on users;
create policy "public read" on users for select using (true);

create table if not exists contracts (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table contracts enable row level security;
drop policy if exists "public read" on contracts;
create policy "public read" on contracts for select using (true);

create table if not exists groups (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table groups enable row level security;
drop policy if exists "public read" on groups;
create policy "public read" on groups for select using (true);

create table if not exists txns (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table txns enable row level security;
drop policy if exists "public read" on txns;
create policy "public read" on txns for select using (true);

create table if not exists bets (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table bets enable row level security;
drop policy if exists "public read" on bets;
create policy "public read" on bets for select using (true);

create table if not exists comments (
    id text not null primary key,
    data jsonb not null,
    fs_updated_time timestamp not null
);
alter table comments enable row level security;
drop policy if exists "public read" on comments;
create policy "public read" on comments for select using (true);

create table if not exists incoming_writes (
  id bigint generated always as identity primary key,
  event_id text null, /* can be null for writes generated by manual import */
  doc_kind text not null,
  write_kind text not null,
  doc_id text not null,
  data jsonb null, /* can be null on deletes */
  ts timestamp not null
);
alter table incoming_writes enable row level security;
create index if not exists incoming_writes_ts on incoming_writes (ts desc);

create or replace function get_document_table(doc_kind text)
  returns text
  language plpgsql
as
$$
begin
  return case doc_kind
    when 'txn' then 'txns'
    when 'user' then 'users'
    when 'group' then 'groups'
    when 'contract' then 'contracts'
    when 'contractBet' then 'bets'
    when 'contractComment' then 'comments'
    else null
  end;
end
$$;

create or replace function replicate_writes_process_one(r incoming_writes)
  returns boolean
  language plpgsql
as
$$
declare dest_table text;
begin
  dest_table = get_document_table(r.doc_kind);
  if dest_table = null then
    raise warning 'Invalid document kind.';
    return false;
  end if;
  if r.write_kind = 'create' or r.write_kind = 'update' then
    execute format(
      'insert into %1$I (id, data, fs_updated_time) values (%2$L, %3$L, %4$L)
       on conflict (id) do update set data = %3$L, fs_updated_time = %4$L
       where %1$I.fs_updated_time <= %4$L
       returning id;',
      dest_table, r.doc_id, r.data, r.ts
    );
  elsif r.write_kind = 'delete' then
    execute format(
      'delete from %1$I where id = %2$L and fs_updated_time <= %3$L',
      dest_table, r.doc_id, r.ts
    );
  else
    raise warning 'Invalid write kind.';
    return false;
  end if;
  return true;
end
$$;

/* when processing batches of writes, we order by document ID to avoid deadlocks
   when incoming write batches hit the same documents with new writes in different
   sequences. */

/* todo: we could process batches more efficiently by doing batch modifications for
   each destination table in the batch, but likely not important right now */

create or replace function replicate_writes_process_since(since timestamp)
  returns table(id bigint, succeeded boolean)
  language plpgsql
as
$$
begin
  return query select r.id, replicate_writes_process_one(r) as succeeded
  from incoming_writes as r
  where r.ts >= since
  order by r.doc_id;
end
$$;

create or replace function replicate_writes_process_new()
  returns trigger
  language plpgsql
as
$$
begin
  perform r.id, replicate_writes_process_one(r) as succeeded
  from new_table as r
  order by r.doc_id;
  return null;
end
$$;

drop trigger if exists replicate_writes on incoming_writes;
create trigger replicate_writes
after insert on incoming_writes
referencing new table as new_table
for each statement
execute function replicate_writes_process_new();

begin;
  drop publication if exists supabase_realtime;
  create publication supabase_realtime;
  alter publication supabase_realtime add table users;
  alter publication supabase_realtime add table contracts;
  alter publication supabase_realtime add table groups;
  alter publication supabase_realtime add table txns;
  alter publication supabase_realtime add table bets;
  alter publication supabase_realtime add table comments;
commit;
